{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMjY8Qi+VT9LGdFdsWykWc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasterBeard/Image-Augmentation/blob/main/Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tushare"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwLbuyoOZQ1H",
        "outputId": "b8e43f57-f343-4f67-ce25-161988821417"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tushare\n",
            "  Downloading tushare-1.4.6-py3-none-any.whl (255 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/255.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/255.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.5/255.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tushare) (2.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tushare) (2.31.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from tushare) (4.9.4)\n",
            "Collecting simplejson (from tushare)\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bs4 (from tushare)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Collecting websocket-client==0.57.0 (from tushare)\n",
            "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tushare) (4.66.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from websocket-client==0.57.0->tushare) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->tushare) (4.12.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tushare) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tushare) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tushare) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->tushare) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tushare) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tushare) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tushare) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tushare) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->tushare) (2.5)\n",
            "Installing collected packages: websocket-client, simplejson, bs4, tushare\n",
            "  Attempting uninstall: websocket-client\n",
            "    Found existing installation: websocket-client 1.8.0\n",
            "    Uninstalling websocket-client-1.8.0:\n",
            "      Successfully uninstalled websocket-client-1.8.0\n",
            "Successfully installed bs4-0.0.2 simplejson-3.19.2 tushare-1.4.6 websocket-client-0.57.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This notebook explains how to use reverse images to retrain CNN models.**"
      ],
      "metadata": {
        "id": "mxgS6y1wlHDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "leEU1ZcdT3op"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tushare as ts\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Obtain FTSE index data from the Tushare platform."
      ],
      "metadata": {
        "id": "GgrzZ57llgCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pro = ts.pro_api(\"41addd8c3955aea5623099855def5d5ae794632258ad289d8fd02fb6\")\n",
        "name=\"FTSE\"\n",
        "whole_df = pro.index_global(ts_code=name, start_date='20100701', end_date='20240118')\n",
        "whole_df=whole_df.fillna(method='ffill')"
      ],
      "metadata": {
        "id": "b8IDm_AOZiwG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below is used to calculate the slope of the five-day closing prices."
      ],
      "metadata": {
        "id": "VSuhyZqilzUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def next_period_trend(data):\n",
        "    window_size = 5\n",
        "    result = data['close'].rolling(window_size).apply(lambda x: sm.OLS(x, sm.add_constant(range(len(x)))).fit().params[1])\n",
        "    return result"
      ],
      "metadata": {
        "id": "gZxyA5BKZoxv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because this notebook is run on Colab, the following are the steps to read images from Google Drive. If running locally, this can be ignored, and you can directly read the images that have been downloaded."
      ],
      "metadata": {
        "id": "k3QbemObmZPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk8KpommbD-b",
        "outputId": "b2bc73fc-a889-4ec8-d6f9-098847f36612"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/Image Augmentation/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arffRqgUbO0l",
        "outputId": "deb8fb86-d18a-4bf9-a134-555287de1c97"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Image Augmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Read images, one is a normal stock candlestick chart, and the other is a vertically flipped candlestick chart."
      ],
      "metadata": {
        "id": "uk3ON2FsmlDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "whole_image_array=np.load(str(name)+'_image32.npy')#normal\n",
        "re_whole_image_array=np.load(str(name)+'_Re_image32.npy')#vertical"
      ],
      "metadata": {
        "id": "8PRor5feZxmc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the closing price slope."
      ],
      "metadata": {
        "id": "0aUwj7_JnGDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "whole_df=whole_df.sort_values(by=['trade_date'],ascending=[True])\n",
        "slope_n5=next_period_trend(whole_df)\n",
        "forward_label=slope_n5[33:]"
      ],
      "metadata": {
        "id": "Qb899P9wcZEj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Horizontally flip the candlestick images to obtain another two sets of reversed images."
      ],
      "metadata": {
        "id": "oCZunwj2nT_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forward_image_array = whole_image_array\n",
        "backward_image_array = whole_image_array.copy()\n",
        "for i in range(len(whole_image_array)):\n",
        "    backward_image_array[i] = whole_image_array[i][:, ::-1, :]\n",
        "\n",
        "mirrior_image_array = re_whole_image_array\n",
        "mirrior_backward_image_array = re_whole_image_array.copy()\n",
        "for i in range(len(re_whole_image_array)):\n",
        "    mirrior_backward_image_array[i] = re_whole_image_array[i][:, ::-1, :]"
      ],
      "metadata": {
        "id": "PUM7SSwjdbMp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Classify the labels, marking those with a slope greater than 0 as 1, and all others as 0."
      ],
      "metadata": {
        "id": "LrT9Ivpknv99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary=forward_label>0\n",
        "target_label = np.where(binary==True, 1, 0)"
      ],
      "metadata": {
        "id": "EXC78XJOdk0j"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize all images by dividing by 255."
      ],
      "metadata": {
        "id": "WTBEWzH4oAJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backward_image_array = backward_image_array/ 255.0\n",
        "forward_image_array = forward_image_array/ 255.0\n",
        "mirrior_backward_image_array = mirrior_backward_image_array/ 255.0\n",
        "mirrior_image_array = mirrior_image_array/255.0"
      ],
      "metadata": {
        "id": "k7Ls5nLXduJS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue with the division of training, validation, and test sets."
      ],
      "metadata": {
        "id": "1OfRyuYmoUTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_image,test_image,train_label,test_label=train_test_split(forward_image_array,target_label,test_size=0.16,random_state=10)\n",
        "train_image,val_image,train_label,val_label=train_test_split(train_image,train_label,test_size=0.2/0.84,random_state=10)"
      ],
      "metadata": {
        "id": "T0f5znOCfRtA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comprising 2169, 678, and 543 images, respectively.\n",
        "train_image.shape[0],val_image.shape[0],test_image.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uq3jfrDfs2Q",
        "outputId": "612dfead-d8f4-47cc-df39-2aeea28fb0f5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2169, 678, 543)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Construct the CNN model architecture."
      ],
      "metadata": {
        "id": "G_oGi9cnoWvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model():\n",
        "    model = Sequential([\n",
        "\n",
        "        layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "\n",
        "        layers.Dense(2, name=\"outputs\")\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "NHKvYcdbespD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1rty8yhfpQW",
        "outputId": "37b9fa41-ef43-4f60-cba7-2d12be60ed8a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       36992     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " outputs (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 448002 (1.71 MB)\n",
            "Trainable params: 448002 (1.71 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Establish an early stopping mechanism."
      ],
      "metadata": {
        "id": "hFLHrvj6oguk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    mode='min',\n",
        "    restore_best_weights=True)"
      ],
      "metadata": {
        "id": "b-5j04GTfmay"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history=model.fit(train_image, train_label, epochs=50,callbacks = [early_stopping],verbose=1,\n",
        "                validation_data=(val_image, val_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnOxuPfLgXpH",
        "outputId": "7d5a3c91-b94c-4fb9-ce83-1568f4c05f8c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "68/68 [==============================] - 11s 128ms/step - loss: 0.6953 - accuracy: 0.5265 - val_loss: 0.6899 - val_accuracy: 0.5678\n",
            "Epoch 2/50\n",
            "68/68 [==============================] - 10s 149ms/step - loss: 0.6882 - accuracy: 0.5362 - val_loss: 0.6850 - val_accuracy: 0.5369\n",
            "Epoch 3/50\n",
            "68/68 [==============================] - 8s 113ms/step - loss: 0.6824 - accuracy: 0.5542 - val_loss: 0.6822 - val_accuracy: 0.5324\n",
            "Epoch 4/50\n",
            "68/68 [==============================] - 11s 160ms/step - loss: 0.6770 - accuracy: 0.5768 - val_loss: 0.6835 - val_accuracy: 0.5310\n",
            "Epoch 5/50\n",
            "68/68 [==============================] - 9s 137ms/step - loss: 0.6681 - accuracy: 0.5722 - val_loss: 0.6702 - val_accuracy: 0.5782\n",
            "Epoch 6/50\n",
            "68/68 [==============================] - 9s 125ms/step - loss: 0.6495 - accuracy: 0.6279 - val_loss: 0.6643 - val_accuracy: 0.6077\n",
            "Epoch 7/50\n",
            "68/68 [==============================] - 10s 153ms/step - loss: 0.6269 - accuracy: 0.6478 - val_loss: 0.6446 - val_accuracy: 0.6209\n",
            "Epoch 8/50\n",
            "68/68 [==============================] - 8s 114ms/step - loss: 0.5796 - accuracy: 0.7017 - val_loss: 0.6466 - val_accuracy: 0.6254\n",
            "Epoch 9/50\n",
            "68/68 [==============================] - 10s 148ms/step - loss: 0.5287 - accuracy: 0.7391 - val_loss: 0.6438 - val_accuracy: 0.6490\n",
            "Epoch 10/50\n",
            "68/68 [==============================] - 8s 124ms/step - loss: 0.4653 - accuracy: 0.7796 - val_loss: 0.6711 - val_accuracy: 0.6327\n",
            "Epoch 11/50\n",
            "68/68 [==============================] - 9s 136ms/step - loss: 0.3726 - accuracy: 0.8396 - val_loss: 0.6544 - val_accuracy: 0.6504\n",
            "Epoch 12/50\n",
            "68/68 [==============================] - 10s 150ms/step - loss: 0.2926 - accuracy: 0.8728 - val_loss: 0.7003 - val_accuracy: 0.6652\n",
            "Epoch 13/50\n",
            "68/68 [==============================] - 8s 113ms/step - loss: 0.2244 - accuracy: 0.9069 - val_loss: 0.6757 - val_accuracy: 0.6829\n",
            "Epoch 14/50\n",
            "68/68 [==============================] - 15s 221ms/step - loss: 0.1946 - accuracy: 0.9225 - val_loss: 0.7383 - val_accuracy: 0.6652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model(\"Original_model_\"+str(name)+\".h5\")"
      ],
      "metadata": {
        "id": "duRqK7INj7EU"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The performance of the original model is as follows:"
      ],
      "metadata": {
        "id": "G5fOd1jRorzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(val_image,  val_label, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(test_image,  test_label, verbose=0)\n",
        "print(test_loss, test_acc)\n",
        "print(val_loss, val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZiqPrdGhRDb",
        "outputId": "474c9b0c-d5db-42b5-db92-fac918d8f12c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6679201126098633 0.6261510252952576\n",
            "0.6437720656394958 0.6489675641059875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the original model"
      ],
      "metadata": {
        "id": "QLt3SzO9o4dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Best_model_\"+str(name)+\".h5\")\n",
        "model.save(\"Original_model_\"+str(name)+\".h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBU6_FY8h2ML",
        "outputId": "3803e330-531e-40cb-9229-7e863d7a2a89"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine all reversed images into one dataset for convenient random sampling later."
      ],
      "metadata": {
        "id": "SKHAeC2ho-oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "com_train_image=np.concatenate((backward_image_array,mirrior_image_array,mirrior_backward_image_array),axis=0)"
      ],
      "metadata": {
        "id": "36_QcmJgh9sR"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Below is the random selection of 5,000 reversed and normal candlestick images to compose new training images. The original model will enter this algorithm, and models without improvement will be eliminated, keeping only those that show improvement. The process is set to repeat 10 times."
      ],
      "metadata": {
        "id": "OcG1vZKppOF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 5000\n",
        "\n",
        "for i in range(10):\n",
        "    index = np.random.choice(com_train_image.shape[0], int(n), replace=False)\n",
        "    x_random = com_train_image[index]\n",
        "    y_random = np.random.randint(0,2, size = x_random.shape[0])\n",
        "    x_random = np.concatenate((x_random,train_image),axis=0)\n",
        "    y_random = np.concatenate((y_random,train_label),axis=0)\n",
        "    order = np.arange(len(y_random))\n",
        "    np.random.shuffle(order)\n",
        "    x_random = x_random[order]\n",
        "    y_random = y_random[order]\n",
        "\n",
        "    history = model.fit(x_random, y_random, epochs=100,callbacks = [early_stopping],verbose=0,\n",
        "                validation_data=(val_image, val_label))\n",
        "    new_loss, new_acc = model.evaluate(val_image,  val_label, verbose=0)\n",
        "\n",
        "    if  new_loss<val_loss:\n",
        "        model.save(\"Best_model_\"+str(name)+\".h5\")\n",
        "        val_loss = new_loss\n",
        "        val_acc = new_acc\n",
        "\n",
        "        print(i,new_loss,new_acc)\n",
        "\n",
        "    else:\n",
        "        #continue\n",
        "        print('fail'+str(i),new_loss,new_acc)\n",
        "        model = keras.models.load_model(\"Best_model_\"+str(name)+\".h5\")\n",
        "\n",
        "val_loss, val_acc = model.evaluate(val_image,  val_label, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(test_image,  test_label, verbose=0)\n",
        "print(test_loss, test_acc)\n",
        "print(val_loss, val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3KA3i2wiHrJ",
        "outputId": "c9bb96e4-d65b-4063-c03d-ccb9a4246d5e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.6271610856056213 0.6504424810409546\n",
            "fail1 0.631825864315033 0.6445427536964417\n",
            "2 0.6264476180076599 0.6533923149108887\n",
            "fail3 0.640033483505249 0.6637167930603027\n",
            "fail4 0.6365007758140564 0.6474926471710205\n",
            "fail5 0.6621963977813721 0.6622418761253357\n",
            "fail6 0.6828692555427551 0.6415929198265076\n",
            "fail7 0.6493455767631531 0.6563422083854675\n",
            "fail8 0.6676269173622131 0.6342182755470276\n",
            "fail9 0.6385443806648254 0.6401180028915405\n",
            "0.6651716232299805 0.6482504606246948\n",
            "0.6264476180076599 0.6533923149108887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After two improvements, our model achieved an accuracy of 64.82% on the test set, and the loss on the validation set was reduced to 0.6264 (before retraining, it was 0.6437)."
      ],
      "metadata": {
        "id": "5R1GlThOtvg6"
      }
    }
  ]
}
